{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS, GPSTAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.75  # THRESHOLD\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "model = keras.models.load_model('./traffic_sign_model.h5') #load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassName(classNo):\n",
    "    if classNo == 0:\n",
    "        return 'Speed Limit 20 km/h'\n",
    "    elif classNo == 1:\n",
    "        return 'Speed Limit 30 km/h'\n",
    "    elif classNo == 2:\n",
    "        return 'Speed Limit 50 km/h'\n",
    "    elif classNo == 3:\n",
    "        return 'Speed Limit 60 km/h'\n",
    "    elif classNo == 4:\n",
    "        return 'Speed Limit 70 km/h'\n",
    "    elif classNo == 5:\n",
    "        return 'Speed Limit 80 km/h'\n",
    "    elif classNo == 6:\n",
    "        return 'End of Speed Limit 80 km/h'\n",
    "    elif classNo == 7:\n",
    "        return 'Speed Limit 100 km/h'\n",
    "    elif classNo == 8:\n",
    "        return 'Speed Limit 120 km/h'\n",
    "    elif classNo == 9:\n",
    "        return 'No passing'\n",
    "    elif classNo == 10:\n",
    "        return 'No passing for vechiles over 3.5 metric tons'\n",
    "    elif classNo == 11:\n",
    "        return 'Right-of-way at the next intersection'\n",
    "    elif classNo == 12:\n",
    "        return 'Priority road'\n",
    "    elif classNo == 13:\n",
    "        return 'Yield'\n",
    "    elif classNo == 14:\n",
    "        return 'Stop'\n",
    "    elif classNo == 15:\n",
    "        return 'No vechiles'\n",
    "    elif classNo == 16:\n",
    "        return 'Vechiles over 3.5 metric tons prohibited'\n",
    "    elif classNo == 17:\n",
    "        return 'No entry'\n",
    "    elif classNo == 18:\n",
    "        return 'General caution'\n",
    "    elif classNo == 19:\n",
    "        return 'Dangerous curve to the left'\n",
    "    elif classNo == 20:\n",
    "        return 'Dangerous curve to the right'\n",
    "    elif classNo == 21:\n",
    "        return 'Double curve'\n",
    "    elif classNo == 22:\n",
    "        return 'Bumpy road'\n",
    "    elif classNo == 23:\n",
    "        return 'Slippery road'\n",
    "    elif classNo == 24:\n",
    "        return 'Road narrows on the right'\n",
    "    elif classNo == 25:\n",
    "        return 'Road work'\n",
    "    elif classNo == 26:\n",
    "        return 'Traffic signals'\n",
    "    elif classNo == 27:\n",
    "        return 'Pedestrians'\n",
    "    elif classNo == 28:\n",
    "        return 'Children crossing'\n",
    "    elif classNo == 29:\n",
    "        return 'Bicycles crossing'\n",
    "    elif classNo == 30:\n",
    "        return 'Beware of ice/snow'\n",
    "    elif classNo == 31:\n",
    "        return 'Wild animals crossing'\n",
    "    elif classNo == 32:\n",
    "        return 'End of all speed and passing limits'\n",
    "    elif classNo == 33:\n",
    "        return 'Turn right ahead'\n",
    "    elif classNo == 34:\n",
    "        return 'Turn left ahead'\n",
    "    elif classNo == 35:\n",
    "        return 'Ahead only'\n",
    "    elif classNo == 36:\n",
    "        return 'Go straight or right'\n",
    "    elif classNo == 37:\n",
    "        return 'Go straight or left'\n",
    "    elif classNo == 38:\n",
    "        return 'Keep right'\n",
    "    elif classNo == 39:\n",
    "        return 'Keep left'\n",
    "    elif classNo == 40:\n",
    "        return 'Roundabout mandatory'\n",
    "    elif classNo == 41:\n",
    "        return 'End of no passing'\n",
    "    elif classNo == 42:\n",
    "        return 'End of no passing by vechiles over 3.5 metric tons'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction de pretraitement des images \n",
    "\n",
    "def preprocess_img(imgBGR, erode_dilate=True):  # pre-processing fro detect signs in  image.\n",
    "    rows, cols, _ = imgBGR.shape\n",
    "    imgHSV = cv2.cvtColor(imgBGR, cv2.COLOR_BGR2HSV)\n",
    "    Bmin = np.array([100, 43, 46])\n",
    "    Bmax = np.array([124, 255, 255])\n",
    "    img_Bbin = cv2.inRange(imgHSV, Bmin, Bmax)\n",
    "\n",
    "    Rmin1 = np.array([0, 43, 46])\n",
    "    Rmax1 = np.array([10, 255, 255])\n",
    "    img_Rbin1 = cv2.inRange(imgHSV, Rmin1, Rmax1)\n",
    "\n",
    "    Rmin2 = np.array([156, 43, 46])\n",
    "    Rmax2 = np.array([180, 255, 255])\n",
    "    img_Rbin2 = cv2.inRange(imgHSV, Rmin2, Rmax2)\n",
    "    img_Rbin = np.maximum(img_Rbin1, img_Rbin2)\n",
    "    img_bin = np.maximum(img_Bbin, img_Rbin)\n",
    "\n",
    "    if erode_dilate is True:\n",
    "        kernelErosion = np.ones((3, 3), np.uint8)\n",
    "        kernelDilation = np.ones((3, 3), np.uint8)\n",
    "        img_bin = cv2.erode(img_bin, kernelErosion, iterations=2)\n",
    "        img_bin = cv2.dilate(img_bin, kernelDilation, iterations=2)\n",
    "\n",
    "    return img_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def contour_detect(img_bin, min_area, max_area=-1, wh_ratio=2.0, aspect_ratio_threshold=0.4):\\n    rects = []\\n    contours, _ = cv2.findContours(img_bin.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) \\n    if len(contours) == 0:\\n        return rects\\n\\n    max_area = img_bin.shape[0] * img_bin.shape[1] if max_area < 0 else max_area\\n    for contour in contours:\\n        area = cv2.contourArea(contour)\\n        if area >= min_area and area <= max_area:\\n            x, y, w, h = cv2.boundingRect(contour)\\n            aspect_ratio = 1.0 * w / h\\n            if aspect_ratio_threshold * wh_ratio <= aspect_ratio <= wh_ratio / aspect_ratio_threshold:\\n                rects.append([x, y, w, h])\\n    return rects\\n    '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def contour_detect(img_bin, min_area, max_area=-1, wh_ratio=2.0):\n",
    "    rects = []\n",
    "    contours, _ = cv2.findContours(img_bin.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) \n",
    "    if len(contours) == 0:\n",
    "        return rects\n",
    "\n",
    "    max_area = img_bin.shape[0] * img_bin.shape[1] if max_area < 0 else max_area\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area >= min_area and area <= max_area:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            if 1.0 * w / h < wh_ratio and 1.0 * h / w < wh_ratio:\n",
    "                rects.append([x, y, w, h])\n",
    "    return rects\n",
    "\n",
    "\n",
    "\"\"\"def contour_detect(img_bin, min_area, max_area=-1, wh_ratio=2.0, aspect_ratio_threshold=0.4):\n",
    "    rects = []\n",
    "    contours, _ = cv2.findContours(img_bin.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) \n",
    "    if len(contours) == 0:\n",
    "        return rects\n",
    "\n",
    "    max_area = img_bin.shape[0] * img_bin.shape[1] if max_area < 0 else max_area\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area >= min_area and area <= max_area:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            aspect_ratio = 1.0 * w / h\n",
    "            if aspect_ratio_threshold * wh_ratio <= aspect_ratio <= wh_ratio / aspect_ratio_threshold:\n",
    "                rects.append([x, y, w, h])\n",
    "    return rects\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img\n",
    "\n",
    "\n",
    "def equalize(img):\n",
    "    img = cv2.equalizeHist(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def preprocessing(img):\n",
    "    img = grayscale(img)\n",
    "    img = equalize(img)\n",
    "    img = img / 255\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction principale pour lire la video et detecter le panneau dessus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    video_path = '../../../files/video.mp4'\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    cols = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    rows = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    cv2.namedWindow(\"Video\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"Video\", cols, rows)\n",
    "    \n",
    "\n",
    "    while (1):\n",
    "        ret, img = cap.read()\n",
    "        img_bin = preprocess_img(img, False);cv2.imshow(\"bin image\", img_bin)\n",
    "        min_area = img_bin.shape[0] * img.shape[1] / (25 * 25)\n",
    "        rects = contour_detect(img_bin, min_area=min_area)   # get x,y,h and w.\n",
    "        img_bbx = img.copy()\n",
    "        \n",
    "        for rect in rects:\n",
    "            xc = int(rect[0] + rect[2] / 2)\n",
    "            yc = int(rect[1] + rect[3] / 2)\n",
    "\n",
    "            size = max(rect[2], rect[3])\n",
    "            x1 = max(0, int(xc - size / 2))\n",
    "            y1 = max(0, int(yc - size / 2))\n",
    "            x2 = min(cols, int(xc + size / 2))\n",
    "            y2 = min(rows, int(yc + size / 2))\n",
    "\n",
    "            # rect[2] is width and rect[3] for height\n",
    "            if rect[2] > 100 and rect[3] > 100:             #only detect those signs whose height and width >100\n",
    "                cv2.rectangle(img_bbx, (rect[0], rect[1]), (rect[0] + rect[2], rect[1] + rect[3]), (0, 0, 255), 2)\n",
    "            crop_img = np.asarray(img[y1:y2, x1:x2])\n",
    "            crop_img = cv2.resize(crop_img, (32, 32))\n",
    "            crop_img = preprocessing(crop_img)\n",
    "            cv2.imshow(\"afterprocessing\", crop_img)\n",
    "            crop_img = crop_img.reshape(1, 32, 32, 1)       # (1,32,32) after reshape it become (1,32,32,1)\n",
    "            predictions = model.predict(crop_img)           # make predicion\n",
    "            classIndex = np.argmax(predictions)\n",
    "            probabilityValue = np.amax(predictions)\n",
    "            if probabilityValue > threshold:\n",
    "                #write class name on the output screen\n",
    "                speed_limit = cv2.putText(img_bbx, str(classIndex) + \" \" + str(getClassName(classIndex)), (rect[0], rect[1] - 10),\n",
    "                            font, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "                # write probability value on the output screen\n",
    "                cv2.putText(img_bbx, str(round(probabilityValue * 100, 2)) + \"%\", (rect[0], rect[1] - 40), font, 0.75,\n",
    "                            (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow(\"detect result\", img_bbx)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):           # q for quit \n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction des informations gps sur la video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aucune information GPS trouvée dans la vidéo.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import piexif\n",
    "from PIL import Image\n",
    "\n",
    "def extract_gps_from_video(video_path):\n",
    "    # Ouvrir la vidéo à l'aide d'OpenCV\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Liste pour stocker les coordonnées GPS\n",
    "    gps_coordinates = []\n",
    "\n",
    "    # Lire chaque frame de la vidéo\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convertir la frame en format PIL Image pour extraire les métadonnées EXIF\n",
    "        pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        # Extraire les métadonnées EXIF\n",
    "        exif_data = pil_image.info.get('exif')\n",
    "\n",
    "        if exif_data:\n",
    "            # Vérifier si les métadonnées GPS sont présentes\n",
    "            if piexif.GPSIFD.GPSLatitude in exif_data and piexif.GPSIFD.GPSLongitude in exif_data:\n",
    "                latitude = exif_data[piexif.GPSIFD.GPSLatitude]\n",
    "                longitude = exif_data[piexif.GPSIFD.GPSLongitude]\n",
    "\n",
    "                # Convertir les coordonnées GPS en degrés décimaux\n",
    "                latitude_decimal = latitude[0][0] / latitude[0][1] + latitude[1][0] / latitude[1][1] / 60 + latitude[2][0] / latitude[2][1] / 3600\n",
    "                longitude_decimal = longitude[0][0] / longitude[0][1] + longitude[1][0] / longitude[1][1] / 60 + longitude[2][0] / longitude[2][1] / 3600\n",
    "\n",
    "                # Ajouter les coordonnées GPS à la liste\n",
    "                gps_coordinates.append((latitude_decimal, longitude_decimal))\n",
    "\n",
    "    # Fermer la capture vidéo\n",
    "    cap.release()\n",
    "\n",
    "    return gps_coordinates\n",
    "\n",
    "# Exemple d'utilisation\n",
    "video_path = \"../../files/vid4.mp4\"\n",
    "gps_coordinates = extract_gps_from_video(video_path)\n",
    "\n",
    "if gps_coordinates:\n",
    "    for i, (latitude, longitude) in enumerate(gps_coordinates):\n",
    "        print(f\"Frame {i+1}: Latitude: {latitude}, Longitude: {longitude}\")\n",
    "else:\n",
    "    print(\"Aucune information GPS trouvée dans la vidéo.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gps_info(photo_path):\n",
    "    try:\n",
    "        img = Image.open(photo_path)\n",
    "        exif_data = img._getexif()\n",
    "        if exif_data is not None:\n",
    "            for tag, value in exif_data.items():\n",
    "                tag_name = TAGS.get(tag, tag)\n",
    "                if tag_name == \"GPSInfo\":\n",
    "                    return value\n",
    "    except (AttributeError, KeyError, IndexError):\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def decimal_to_dms(value):\n",
    "    degrees = int(value)\n",
    "    minutes = int((value - degrees) * 60)\n",
    "    seconds = int((value - degrees - minutes / 60) * 3600)\n",
    "    return degrees, minutes, seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction des donnees gps sur l'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latitude: 4.069917194444444\n",
      "Longitude: 9.726550083333333\n"
     ]
    }
   ],
   "source": [
    "def get_geolocation(exif_data):\n",
    "    # Coordonnées par défaut (au cas où les données GPS ne sont pas présentes)\n",
    "    latitude = None\n",
    "    longitude = None\n",
    "\n",
    "    # Vérifier si les données GPS sont présentes dans les métadonnées EXIF\n",
    "    if 'GPSInfo' in exif_data:\n",
    "        # Convertir les valeurs degré/minute/seconde en degrés décimaux\n",
    "        def convert_to_degrees(value):\n",
    "            d = value[0]\n",
    "            m = value[1]\n",
    "            s = value[2]\n",
    "            return d + (m / 60.0) + (s / 3600.0)\n",
    "\n",
    "        # Extraire les informations GPS\n",
    "        gps_info = exif_data['GPSInfo']\n",
    "        gps_latitude = gps_info.get(2)\n",
    "        gps_latitude_ref = gps_info.get(1)\n",
    "        gps_longitude = gps_info.get(4)\n",
    "        gps_longitude_ref = gps_info.get(3)\n",
    "\n",
    "        if gps_latitude and gps_latitude_ref and gps_longitude and gps_longitude_ref:\n",
    "            latitude = convert_to_degrees(gps_latitude)\n",
    "            if gps_latitude_ref != 'N':\n",
    "                latitude = -latitude\n",
    "\n",
    "            longitude = convert_to_degrees(gps_longitude)\n",
    "            if gps_longitude_ref != 'E':\n",
    "                longitude = -longitude\n",
    "\n",
    "    return latitude, longitude\n",
    "\n",
    "def extract_geolocation_from_photo(photo_path):\n",
    "    # Ouvrir l'image avec PIL\n",
    "    image = Image.open(photo_path)\n",
    "\n",
    "    # Extraire les métadonnées EXIF\n",
    "    exif_data = image._getexif()\n",
    "\n",
    "    # Si les métadonnées EXIF existent, les convertir en un dictionnaire avec des noms explicites\n",
    "    if exif_data is not None:\n",
    "        exif_data = {\n",
    "            TAGS[key]: exif_data[key]\n",
    "            for key in exif_data\n",
    "            if key in TAGS\n",
    "        }\n",
    "\n",
    "    # Obtenir les coordonnées GPS de l'image\n",
    "    latitude, longitude = get_geolocation(exif_data)\n",
    "\n",
    "    return latitude, longitude\n",
    "\n",
    "# Exemple d'utilisation\n",
    "photo_path = \"../../file3.jpg\"\n",
    "latitude, longitude = extract_geolocation_from_photo(photo_path)\n",
    "\n",
    "if latitude is not None and longitude is not None:\n",
    "    print(f\"Latitude: {latitude}\")\n",
    "    print(f\"Longitude: {longitude}\")\n",
    "else:\n",
    "    print(\"Aucune information de géolocalisation trouvée dans la photo.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction principale pour lire l'image, detecter le panneau dessus et renvoyer les informations gps s'il y en a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPS Coordinates:\n",
      "Latitude: 4° 4' 44\"\n",
      "Longitude: 9° 47' 25\"\n",
      "1/1 [==============================] - 0s 371ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    photo_path = '../../files/IMG_20230805_112320_984.jpg'  # Replace this with the path to your photo\n",
    "    img = cv2.imread(photo_path)\n",
    "\n",
    "    img = cv2.resize(img, (550, 600), interpolation=cv2.INTER_LINEAR)  # Resize the original image\n",
    "\n",
    "    img_bin = preprocess_img(img, False)\n",
    "    min_area = img_bin.shape[0] * img.shape[1] / (25 * 25)\n",
    "    rects = contour_detect(img_bin, min_area=min_area)\n",
    "    img_bbx = img.copy()\n",
    "\n",
    "    gps_info = get_gps_info(photo_path)\n",
    "    \n",
    "    if gps_info is not None:\n",
    "        latitude = gps_info[2][0] + gps_info[2][1] / 60 + gps_info[2][2] / 3600\n",
    "        longitude = gps_info[4][0] + gps_info[4][1] / 60 + gps_info[4][2] / 3600\n",
    "        lat_deg, lat_min, lat_sec = decimal_to_dms(latitude)\n",
    "        lon_deg, lon_min, lon_sec = decimal_to_dms(longitude)\n",
    "\n",
    "        print(\"GPS Coordinates:\")\n",
    "        print(f\"Latitude: {lat_deg}° {lat_min}' {lat_sec}\\\"\")\n",
    "        print(f\"Longitude: {lon_deg}° {lon_min}' {lon_sec}\\\"\")\n",
    "        \n",
    "    else: \n",
    "        print('No gps information')\n",
    "\n",
    "    for rect in rects:\n",
    "        xc = int(rect[0] + rect[2] / 2)\n",
    "        yc = int(rect[1] + rect[3] / 2)\n",
    "\n",
    "        size = max(rect[2], rect[3])\n",
    "        x1 = max(0, int(xc - size / 2))\n",
    "        y1 = max(0, int(yc - size / 2))\n",
    "        x2 = min(img.shape[1], int(xc + size / 2))\n",
    "        y2 = min(img.shape[0], int(yc + size / 2))\n",
    "\n",
    "        if rect[2] > 100 and rect[3] > 100:\n",
    "            cv2.rectangle(img_bbx, (rect[0], rect[1]), (rect[0] + rect[2], rect[1] + rect[3]), (0, 0, 255), 2)\n",
    "\n",
    "        crop_img = np.asarray(img[y1:y2, x1:x2])\n",
    "        crop_img = cv2.resize(crop_img, (32, 32))\n",
    "        crop_img = preprocessing(crop_img)\n",
    "        crop_img = crop_img.reshape(1, 32, 32, 1)\n",
    "\n",
    "        # Assume 'model' and 'getClassName' are properly defined for image recognition\n",
    "        predictions = model.predict(crop_img)\n",
    "        classIndex = np.argmax(predictions)\n",
    "        probabilityValue = np.amax(predictions)\n",
    "        threshold = 0.5  # You can adjust the threshold value as needed\n",
    "\n",
    "        if probabilityValue > threshold:\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            cv2.putText(img_bbx, str(classIndex) + \" \" + str(getClassName(classIndex)),\n",
    "                        (rect[0], rect[1] - 10), font, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            cv2.putText(img_bbx, str(round(probabilityValue * 100, 2)) + \"%\",\n",
    "                        (rect[0], rect[1] - 40), font, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(\"detect result\", img_bbx)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No gps information\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "\n",
    "def detect_panels_on_image():\n",
    "    global img_path\n",
    "    photo_path = filedialog.askopenfilename(initialdir=\"/\", title=\"Select an Image\", filetypes=[(\"Image files\", \"*.png;*.jpg;*.jpeg;*.gif\")])\n",
    "    if photo_path:\n",
    "        img = cv2.imread(photo_path)\n",
    "\n",
    "        img = cv2.resize(img, (550, 600), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "        img_bin = preprocess_img(img, False)\n",
    "        min_area = img_bin.shape[0] * img.shape[1] / (25 * 25)\n",
    "        rects = contour_detect(img_bin, min_area)\n",
    "        img_bbx = img.copy()\n",
    "\n",
    "        gps_info = get_gps_info(photo_path)\n",
    "        \n",
    "        if gps_info is not None:\n",
    "            latitude = gps_info[2][0] + gps_info[2][1] / 60 + gps_info[2][2] / 3600\n",
    "            longitude = gps_info[4][0] + gps_info[4][1] / 60 + gps_info[4][2] / 3600\n",
    "            lat_deg, lat_min, lat_sec = decimal_to_dms(latitude)\n",
    "            lon_deg, lon_min, lon_sec = decimal_to_dms(longitude)\n",
    "\n",
    "            print(\"GPS Coordinates:\")\n",
    "            print(f\"Latitude: {lat_deg}° {lat_min}' {lat_sec}\\\"\")\n",
    "            print(f\"Longitude: {lon_deg}° {lon_min}' {lon_sec}\\\"\")\n",
    "            \n",
    "        else: \n",
    "            print('No gps information')\n",
    "\n",
    "        for rect in rects:\n",
    "            xc = int(rect[0] + rect[2] / 2)\n",
    "            yc = int(rect[1] + rect[3] / 2)\n",
    "\n",
    "            size = max(rect[2], rect[3])\n",
    "            x1 = max(0, int(xc - size / 2))\n",
    "            y1 = max(0, int(yc - size / 2))\n",
    "            x2 = min(img.shape[1], int(xc + size / 2))\n",
    "            y2 = min(img.shape[0], int(yc + size / 2))\n",
    "\n",
    "            if rect[2] > 100 and rect[3] > 100:\n",
    "                cv2.rectangle(img_bbx, (rect[0], rect[1]), (rect[0] + rect[2], rect[1] + rect[3]), (0, 0, 255), 2)\n",
    "\n",
    "            crop_img = np.asarray(img[y1:y2, x1:x2])\n",
    "            crop_img = cv2.resize(crop_img, (32, 32))\n",
    "            crop_img = preprocessing(crop_img)\n",
    "            crop_img = crop_img.reshape(1, 32, 32, 1)\n",
    "\n",
    "            # Assume 'model' and 'getClassName' are properly defined for image recognition\n",
    "            predictions = model.predict(crop_img)\n",
    "            classIndex = np.argmax(predictions)\n",
    "            probabilityValue = np.amax(predictions)\n",
    "            threshold = 0.5\n",
    "\n",
    "            if probabilityValue > threshold:\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                cv2.putText(img_bbx, str(classIndex) + \" \" + str(getClassName(classIndex)),\n",
    "                            (rect[0], rect[1] - 10), font, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "                cv2.putText(img_bbx, str(round(probabilityValue * 100, 2)) + \"%\",\n",
    "                            (rect[0], rect[1] - 40), font, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        cv2.imshow(\"detect result\", img_bbx)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "def detect_panels_on_video():\n",
    "    video_path = filedialog.askopenfilename(initialdir=\"/\", title=\"Select a Video\", filetypes=[(\"Video files\", \"*.mp4;*.avi\")])\n",
    "    if video_path:\n",
    "        video_capture = cv2.VideoCapture(video_path)\n",
    "\n",
    "        while True:\n",
    "            ret, frame = video_capture.read()\n",
    "\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            frame = cv2.resize(frame, (550, 600), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "            img_bin = preprocess_img(frame, False)\n",
    "            min_area = img_bin.shape[0] * frame.shape[1] / (25 * 25)\n",
    "            rects = contour_detect(img_bin, min_area)\n",
    "            img_bbx = frame.copy()\n",
    "\n",
    "            #gps_info = get_gps_info(photo_path)\n",
    "        \n",
    "            \"\"\"if extract_gps_from_video is not None:\n",
    "                latitude = extract_gps_from_video[2][0] + extract_gps_from_video[2][1] / 60 + extract_gps_from_video[2][2] / 3600\n",
    "                longitude = extract_gps_from_video[4][0] + extract_gps_from_video[4][1] / 60 + extract_gps_from_video[4][2] / 3600\n",
    "                lat_deg, lat_min, lat_sec = decimal_to_dms(latitude)\n",
    "                lon_deg, lon_min, lon_sec = decimal_to_dms(longitude)\n",
    "\n",
    "                print(\"GPS Coordinates:\")\n",
    "                print(f\"Latitude: {lat_deg}° {lat_min}' {lat_sec}\\\"\")\n",
    "                print(f\"Longitude: {lon_deg}° {lon_min}' {lon_sec}\\\"\")\n",
    "                \n",
    "            else: \n",
    "                print('No gps information')\n",
    "                \"\"\"\n",
    "                \n",
    "            for rect in rects:\n",
    "                xc = int(rect[0] + rect[2] / 2)\n",
    "                yc = int(rect[1] + rect[3] / 2)\n",
    "\n",
    "                size = max(rect[2], rect[3])\n",
    "                x1 = max(0, int(xc - size / 2))\n",
    "                y1 = max(0, int(yc - size / 2))\n",
    "                x2 = min(frame.shape[1], int(xc + size / 2))#\n",
    "                y2 = min(frame.shape[0], int(yc + size / 2))#\n",
    "\n",
    "                if rect[2] > 100 and rect[3] > 100:\n",
    "                    cv2.rectangle(img_bbx, (rect[0], rect[1]), (rect[0] + rect[2], rect[1] + rect[3]), (0, 0, 255), 2)\n",
    "\n",
    "                crop_img = np.asarray(frame[y1:y2, x1:x2])#\n",
    "                crop_img = cv2.resize(crop_img, (32, 32))\n",
    "                crop_img = preprocessing(crop_img)\n",
    "                crop_img = crop_img.reshape(1, 32, 32, 1)\n",
    "\n",
    "                # Assume 'model' and 'getClassName' are properly defined for image recognition\n",
    "                predictions = model.predict(crop_img)\n",
    "                classIndex = np.argmax(predictions)\n",
    "                probabilityValue = np.amax(predictions)\n",
    "                threshold = 0.5\n",
    "\n",
    "            if probabilityValue > threshold:\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                cv2.putText(img_bbx, str(classIndex) + \" \" + str(getClassName(classIndex)),\n",
    "                            (rect[0], rect[1] - 10), font, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "                cv2.putText(img_bbx, str(round(probabilityValue * 100, 2)) + \"%\",\n",
    "                            (rect[0], rect[1] - 40), font, 0.75, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            cv2.imshow(\"detect result\", img_bbx)\n",
    "        # cv2.waitKey(0)\n",
    "        # cv2.destroyAllWindows()\n",
    "\n",
    "        # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        #     break\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        video_capture.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# Create the main application window\n",
    "root = tk.Tk()\n",
    "root.title(\"Image Panel Detection\")\n",
    "root.geometry('300x100')\n",
    "root['bg'] = 'gray'\n",
    "\n",
    "# Function to load image and detect panels\n",
    "def load_image_and_detect():\n",
    "    detect_panels_on_image()\n",
    "\n",
    "# Create the Load Image button\n",
    "load_button = tk.Button(root, text=\"Load Image\", command=load_image_and_detect)\n",
    "load_button.pack(pady=10)\n",
    "\n",
    "detect_video_button = tk.Button(root, text=\"Load Video\", command=detect_panels_on_video)\n",
    "detect_video_button.pack(pady=10)\n",
    "\n",
    "# Start the Tkinter main loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
